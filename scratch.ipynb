{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from fitbit import Fitbit\n",
    "from fitbit import gather_keys_oauth2 as Oauth2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23/Dec/2019:12:11:53] ENGINE Listening for SIGTERM.\n",
      "[23/Dec/2019:12:11:53] ENGINE Listening for SIGHUP.\n",
      "[23/Dec/2019:12:11:53] ENGINE Listening for SIGUSR1.\n",
      "[23/Dec/2019:12:11:53] ENGINE Bus STARTING\n",
      "CherryPy Checker:\n",
      "The Application mounted at '' has an empty config.\n",
      "\n",
      "[23/Dec/2019:12:11:53] ENGINE Started monitor thread 'Autoreloader'.\n",
      "[23/Dec/2019:12:11:53] ENGINE Serving on http://127.0.0.1:8080\n",
      "[23/Dec/2019:12:11:53] ENGINE Bus STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Dec/2019:12:11:55] \"GET /?code=a33283e163302e23f576b4768662ba6c5e7cd83e&state=RYimnME0iTg2az0u8zWKEwm39N1b6u HTTP/1.1\" 200 122 \"\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23/Dec/2019:12:11:56] ENGINE Bus STOPPING\n",
      "[23/Dec/2019:12:11:56] ENGINE HTTP Server cherrypy._cpwsgi_server.CPWSGIServer(('127.0.0.1', 8080)) shut down\n",
      "[23/Dec/2019:12:11:56] ENGINE Stopped thread 'Autoreloader'.\n",
      "[23/Dec/2019:12:11:56] ENGINE Bus STOPPED\n",
      "[23/Dec/2019:12:11:56] ENGINE Bus EXITING\n",
      "[23/Dec/2019:12:11:56] ENGINE Bus EXITED\n",
      "[23/Dec/2019:12:11:56] ENGINE Waiting for child threads to terminate...\n"
     ]
    }
   ],
   "source": [
    "CLIENT_ID = '22B9G6'\n",
    "CLIENT_SECRET = '2b8a440525489bc01643932e5cfc875e'\n",
    "\n",
    "# TODO: Figure out how to authenticate without opening a browser window\n",
    "server = Oauth2.OAuth2Server(CLIENT_ID, CLIENT_SECRET)\n",
    "server.browser_authorize()\n",
    "ACCESS_TOKEN = str(server.fitbit.client.session.token['access_token'])\n",
    "REFRESH_TOKEN = str(server.fitbit.client.session.token['refresh_token'])\n",
    "auth2_client = Fitbit(CLIENT_ID, CLIENT_SECRET, oauth2=True, access_token=ACCESS_TOKEN, refresh_token=REFRESH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set time bounds\n",
    "\n",
    "# First day I wore the fitbit\n",
    "first_day = datetime.datetime(2019,12,12)\n",
    "yesterday = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "\n",
    "# List of date objects from first_day to yesterday \n",
    "# (today's data is still being generated)\n",
    "date_list = [(yesterday - datetime.timedelta(days=i)).date() \n",
    "             for i in range((yesterday - first_day).days + 1)]\n",
    "\n",
    "# List of string-formatted dates\n",
    "str_list = list(map(lambda x: x.strftime(\"%Y-%m-%d\"), date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold all available data in one dict\n",
    "raw = {'heart_sec': [],\n",
    "       'heart_min': [],\n",
    "       'calories': [], \n",
    "       'steps': [], \n",
    "       'floors': [], \n",
    "       'elevation': [],\n",
    "       'sleep': []\n",
    "      }\n",
    "\n",
    "# Sleep data\n",
    "raw['sleep'] = [auth2_client.get_sleep(date) for date in date_list]\n",
    "\n",
    "# Intraday data\n",
    "def get_intraday(resource, interval, date):\n",
    "    return auth2_client.intraday_time_series(\n",
    "        resource = f'activities/{resource}', \n",
    "        base_date=date, \n",
    "        detail_level=f'1{interval}'\n",
    "    )\n",
    "\n",
    "# Pull heart data at 1sec resolution\n",
    "[raw['heart_sec'].append(get_intraday('heart', 'sec', date))\n",
    " for date in str_list\n",
    "];\n",
    "\n",
    "# Pull all intraday data (incl. heart) at 1min resolution\n",
    "[val.append(get_intraday(('heart' if key is 'heart_min' else key), 'min', date))\n",
    " for key, val in raw.items()\n",
    " if key not in ('heart_sec', 'sleep')\n",
    " for date in str_list\n",
    "];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the data into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary data\n",
    "\n",
    "# Construct daily_summary table\n",
    "index = date_list\n",
    "\n",
    "data = {\n",
    "    activity: [int(raw[activity][day][f'activities-{activity}'][0]['value'])\n",
    "               for day in range(len(date_list))\n",
    "              ]\n",
    "    for activity in ('calories', 'steps', 'floors', 'elevation')\n",
    "}\n",
    "\n",
    "daily_summary_df = pd.DataFrame(data=data, index=index)\n",
    "daily_summary_df.index.name = 'datetime'\n",
    "\n",
    "# Construct daily heart tables\n",
    "daily_heart_dfs = {}\n",
    "for zone, table_name in enumerate(\n",
    "    ('daily_oor', 'daily_fat_burn', 'daily_cardio', 'daily_peak')):\n",
    "        data = {\n",
    "            col: [raw['heart_sec'][day][f'activities-heart'][0]['value']['heartRateZones'][0][col]\n",
    "                 for day in range(len(date_list))\n",
    "                ]\n",
    "            for col in ('caloriesOut', 'max', 'min', 'minutes')\n",
    "        }\n",
    "        daily_heart_dfs[table_name] = pd.DataFrame(data=data, index=index)\n",
    "        daily_heart_dfs[table_name].index.name = 'date'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep data\n",
    "\n",
    "# Construct sleep_summary table\n",
    "data = {\n",
    "    'deep': [],\n",
    "    'light': [],\n",
    "    'rem': [], \n",
    "    'wake': [],\n",
    "    'totalMinutesAsleep': [],\n",
    "    'totalTimeInBed': []\n",
    "}\n",
    "\n",
    "[value.append(day['summary'][key])\n",
    " if key in ('totalMinutesAsleep', 'totalTimeInBed')\n",
    " else (value.append(day['summary']['stages'][key])\n",
    "       if 'stages' in day['summary'].keys()\n",
    "       else value.append(None)\n",
    "      )\n",
    " for key, value in data.items()\n",
    " for day in raw['sleep']\n",
    "];\n",
    "\n",
    "index = date_list\n",
    "\n",
    "sleep_summary_df = pd.DataFrame(data=data, index=index)\n",
    "sleep_summary_df.index.name = 'date'\n",
    "\n",
    "# Construct sleep_stage table\n",
    "sleep_by_minute = [{\n",
    "    'datetime': datetime.datetime.combine(\n",
    "        date_list[i], \n",
    "        (parse(record['dateTime'])).time()\n",
    "    ),\n",
    "    'stage': int(record['value'])\n",
    " }\n",
    " for i, day in enumerate(raw['sleep'])\n",
    " for sleep in day['sleep']\n",
    " for record in sleep['minuteData']\n",
    "]\n",
    "\n",
    "index = [record['datetime'] for record in sleep_by_minute]\n",
    "data = [record['stage'] for record in sleep_by_minute]\n",
    "\n",
    "sleep_stage_df = pd.DataFrame(data={'stage': data}, index=index)\n",
    "sleep_stage_df.index.name = 'datetime'\n",
    "\n",
    "# Construct sleep_misc table\n",
    "index = date_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'awakeCount': [],\n",
    "    'awakeDuration': [],\n",
    "    'awakeningsCount': [], \n",
    "    'efficiency': [],\n",
    "    'minutesToFallAsleep': [],\n",
    "    'restlessCount': [],\n",
    "    'restlessDuration': []\n",
    "}\n",
    "\n",
    "[value.append(sleep[key])\n",
    " for key, value in data.items()\n",
    " for i, day in enumerate(raw['sleep'])\n",
    " for sleep in day['sleep']\n",
    "];\n",
    "\n",
    "index = date_list\n",
    "\n",
    "sleep_misc_df = pd.DataFrame(data=data, index=index)\n",
    "sleep_misc_df.index.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building high-res (1sec) heart data df\n",
      "Building series for heart_min...\n",
      "Building series for calories...\n",
      "Building series for steps...\n",
      "Building series for floors...\n",
      "Building series for elevation...\n",
      "Constructing df from series_objs...\n",
      "All dataframes constructed.\n"
     ]
    }
   ],
   "source": [
    "# Intraday data\n",
    "\n",
    "# Put heart_sec in its own df because it's a different time resolution\n",
    "print(\"Building high-res (1sec) heart data df\")\n",
    "index = [datetime.datetime.combine(date_list[i], (parse(record['time'])).time())\n",
    "         for i, day in enumerate(raw['heart_sec'])\n",
    "         for record in day['activities-heart-intraday']['dataset']\n",
    "        ]\n",
    "\n",
    "data = {\n",
    "    'value': [record['value']\n",
    "              for i, day in enumerate(raw['heart_sec'])\n",
    "              for record in day['activities-heart-intraday']['dataset']\n",
    "        ]\n",
    "}\n",
    "\n",
    "heart_df = pd.DataFrame(data=data, index=index)\n",
    "heart_df.index.name = 'datetime'\n",
    "\n",
    "# Put the other intraday data in a single df\n",
    "# This is done by stitching together individual Series objects, \n",
    "# -> because the heart data has a different number of values\n",
    "series_objs = {}\n",
    "\n",
    "for key in raw:\n",
    "    if key not in ('heart_sec', 'sleep'):\n",
    "        print(f'Building series for {key}...')\n",
    "        # Different (coarser) indexes for this data\n",
    "        # Generate a different one for each in case the number of records is different\n",
    "        index = [datetime.datetime.combine(date_list[i], (parse(record['time'])).time())\n",
    "                 for i, day in enumerate(raw[key])\n",
    "                 for record in (day[f'activities-{key}-intraday']['dataset']\n",
    "                                if key is not 'heart_min'\n",
    "                                else day[f'activities-heart-intraday']['dataset']\n",
    "                               )\n",
    "                ]\n",
    "        \n",
    "        data = [record['value']\n",
    "                  for day in raw[key]\n",
    "                  for record in (day[f'activities-{key}-intraday']['dataset']\n",
    "                                 if key is not 'heart_min'\n",
    "                                 else day[f'activities-heart-intraday']['dataset']\n",
    "                                )\n",
    "        ]\n",
    "\n",
    "        series_objs[key] = pd.Series(data=data, index=index)\n",
    "        \n",
    "print(\"Constructing df from series_objs...\")\n",
    "intraday_df = pd.DataFrame(series_objs)\n",
    "intraday_df.index.name = 'datetime'\n",
    "\n",
    "print(\"All dataframes constructed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading dataframes...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "## Upload the data to Postgres\n",
    "print(\"Uploading dataframes...\")\n",
    "\n",
    "# Create database connection\n",
    "engine = create_engine('postgresql://postgres:postgres@localhost:6543/fitbit')\n",
    "\n",
    "# Upload the frames\n",
    "sleep_stage_df.to_sql(name='sleep_stage', con=engine, if_exists='append')\n",
    "heart_df.to_sql(name='heart', con=engine, if_exists='append')\n",
    "intraday_df.to_sql(name='intraday', con=engine, if_exists='append')\n",
    "daily_summary_df.to_sql(name='daily_summary', con=engine, if_exists='append')\n",
    "[df.to_sql(name=table_name, con=engine, if_exists='append')\n",
    " for table_name, df in daily_heart_dfs.items()\n",
    "]\n",
    "sleep_summary_df.to_sql(name='sleep_summary', con=engine, if_exists='append')\n",
    "sleep_misc_df.to_sql(name='sleep_misc', con=engine, if_exists='append')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Put the tables into a database ----\n",
    "# TODO: Define table schema, incl. keys and indexes\n",
    "# TODO: Move the DB to raspberry py\n",
    "\n",
    "# ---- Automatically pull the new data every day ----\n",
    "# TODO: Figure out how to authenticate without opening a browser window\n",
    "# TODO: Write script that pulls just yesterday's data and appends it to the DB\n",
    "# TODO: Run that script automatically every day at midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value    14.988957\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
